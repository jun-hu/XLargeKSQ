---
title: 'Pallab Sarkar - KKBox Music Recommendation EDA'
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: cosmo
    highlight: tango
    code_folding: hide
---
# Introduction
Hey everyone, this is my first EDA notebook.:)
Also a very big thanks to [Heads or Tails](https://www.kaggle.com/headsortails), whose style of creating R based notebooks has been a big help. :)
The initial Exploratory Data Analysis for the [KKBox's Music Recommendation Challenge](https://www.kaggle.com/c/kkbox-music-recommendation-challenge) 
competition is created within the R environment of the [tidyverse](http://tidyverse.org/) and [ggplot2](http://ggplot2.tidyverse.org/). The aim of this challenge is 
to predict the chances of a user listening to a song repetitively after the first observable listening event within a time window was triggered. 
The [data](https://www.kaggle.com/c/kkbox-music-recommendation-challenge/data) comes in the traditional Kaggle form of one training and test file each
: `../input/train.csv` & `../input/test.csv`. Each row corresponds to a specific policy holder and the columns describe their features. 
The target variable is conveniently named *target* here.
# Preparations {.tabset .tabset-fade .tabset-pills}
## Load libraries
We load a range of libraries for general data wrangling and general visualisation together with more specialised tools.
```{r, message = FALSE}
# general visualisation
library('ggplot2') # visualisation
library('scales') # visualisation
library('grid') # visualisation
library('ggthemes') # visualisation
library('gridExtra') # visualisation
library('RColorBrewer') # visualisation
library('corrplot') # visualisation
library('ggpubr') # visualisation
# general data manipulation
library('dplyr') # data manipulation
library('readr') # input/output
library('data.table') # data manipulation
library('tibble') # data wrangling
library('tidyr') # data wrangling
library('stringr') # string manipulation
library('forcats') # factor manipulation
# specific visualisation
library('alluvial') # visualisation
library('ggfortify') # visualisation
library('ggrepel') # visualisation
library('ggridges') # visualisation
library('VIM') # NAs
library('plotly') # interactive
library('ggforce') # visualisation
```
## Helper functions
We use the *multiplot* function, courtesy of [R Cookbooks](http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/) to create multi-panel plots. We also make use of a brief helper function to compute binomial confidence intervals.
```{r}
# Define multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  numPlots = length(plots)
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }
 if (numPlots==1) {
    print(plots[[1]])
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```
```{r echo=FALSE}
# function to extract binomial confidence levels
get_binCI <- function(x,n) as.list(setNames(binom.test(x,n)$conf.int, c("lwr", "upr")))
```
## Load data
We use *data.table's* fread function to speed up reading in the data
```{r warning=FALSE, results=FALSE}
train <- as.tibble(fread('../input/train.csv'))
test <- as.tibble(fread('../input/test.csv'))
songs<-as.tibble(fread('../input/songs.csv'))
members<-as.tibble(fread('../input/members.csv'))
```
# Overview: File structure and content {.tabset .tabset-fade .tabset-pills}
As a first step let's have an overview of the data sets using the *summary* and *glimpse* tools.
## Training data
Summary of training data:
```{r}
summary(train)
```
A glimpse into the training data:
```{r}
glimpse(train)
```
Now let's look into different types of source system tabs:
```{r}
unique(train$source_system_tab)
```
Now let's look into different types of source types:
```{r}
unique(train$source_type)
```
## Songs data
Summary of songs data:
```{r}
summary(songs)
```
A glimpse into the songs data:
```{r}
glimpse(songs)
```
## Members data
Summary of members data:
```{r}
summary(members)
```
A glimpse into the members data:
```{r}
glimpse(members)
```
## Test data
Summary of Test data:
```{r}
summary(test)
```
A glimpse into the test data:
```{r}
glimpse(test)
```
## Data preparation
Let's get the data all together for any exploration with respect to target variable. Let's look into different types of columns the generating dataset have:
```{r}
train$key<-paste(train$msno,train$song_id,sep="_")
test$key<-paste(test$msno,test$song_id,sep="_")
train$id<-row.names(train)
test$target<-''
train$type<-'train'
test$type<-'test'
train1<-train[,c('key','type','id','msno','song_id','source_system_tab','source_screen_name','source_type','target')]
test1<-test[,c('key','type','id','msno','song_id','source_system_tab','source_screen_name','source_type','target')]
rm(train)
rm(test)
master_df<-rbind(train1,test1)
rm(train1)
rm(test1)
colnames(master_df)
```
After adding further columns from songs and members dataset, we have the following columns:
```{r}
master_df_w_song_details<-merge.data.frame(x=master_df,
                                           y=songs,
                                           by=("song_id"),
                                           all.x=TRUE)
master_df_w_song_member_details<-merge.data.frame(x=master_df_w_song_details,
                                                  y=members,
                                                  by=("msno"),
                                                  all.x=TRUE)
rm(master_df_w_song_details)
rm(songs)
rm(members)
master_df_w_song_member_details_train<-master_df_w_song_member_details[master_df_w_song_member_details$type=='train',]
rm(master_df_w_song_member_details)
colnames(master_df_w_song_member_details_train)
```
# Individual feature visualisations {.tabset .tabset-fade .tabset-pills}
Now let's look into the individual features and their relationship with target variables. We will go through each variable type and see their distributions.
## Features from original data
Note the logarithmic y-axes:
```{r  split=FALSE, fig.align = 'default', warning = FALSE, fig.cap ="Fig. 1", out.width="100%"}
p1 <- master_df_w_song_member_details_train %>%
  ggplot(aes(source_system_tab, fill = "#00394C")) +
  geom_bar() +
  scale_y_log10() +
  theme(legend.position = "none")
p2 <- master_df_w_song_member_details_train %>%
  ggplot(aes(source_screen_name, fill = "#00394C")) +
  geom_bar() +
  scale_y_log10() +
  theme(axis.text = element_text(size = 5, colour="black"),legend.position = "none")+coord_flip()
p3 <- master_df_w_song_member_details_train %>%
  ggplot(aes(source_type, fill = "#00394C")) +
  geom_bar() +
  scale_y_log10() +
  theme(legend.position = "none")+coord_flip()
ggarrange(p1,                                                 # First row with scatter plot
          ggarrange(p2, p3, ncol = 2), # Second row with box and dot plots
          nrow = 2
          ) 
```
So as we can see from the training data, people seem to listen more songs through *my library* or through *discover*. Also, they seem to listen to songs from *online playlist*,
*local playlist* or *local library*
## Categorical Features from songs and members data - 1
Now, let's look into frequencies of top 15 genres, artists, composers and songs from the training data. Note the logarithmic y-axes:
```{r  split=FALSE, fig.align = 'default', warning = FALSE, fig.cap ="Fig. 2", out.width="100%"}
d2 <- aggregate(key~genre_ids,data=master_df_w_song_member_details_train,FUN=length)
d2<- d2[order(-d2$key),]
d3<- head(d2,15)
remove(d2)
p1 <- 
  ggplot(d3,aes(genre_ids,key)) +
  geom_bar(stat='identity',fill="#00394C") +
  scale_y_log10() +
  theme(legend.position = "none")+coord_flip()
d2 <- aggregate(key~artist_name,data=master_df_w_song_member_details_train,FUN=length)
d2<- d2[order(-d2$key),]
d3<- head(d2,15)
d3$artist_id<-row.names(d3)
remove(d2)
p2 <- 
  ggplot(d3,aes(artist_id,key)) +
  geom_bar(stat='identity',fill="#00394C") +
  scale_y_log10() +
  theme(legend.position = "none")+coord_flip()
d2 <- aggregate(key~composer,data=master_df_w_song_member_details_train,FUN=length)
d2<- d2[order(-d2$key),]
d3<- head(d2,15)
d3$composer_id<-row.names(d3)
remove(d2)
p3 <- 
  ggplot(d3,aes(composer_id,key)) +
  geom_bar(stat='identity',fill="#00394C") +
  scale_y_log10() +
  theme(legend.position = "none")+coord_flip()
d2 <- aggregate(key~song_id,data=master_df_w_song_member_details_train,FUN=length)
d2<- d2[order(-d2$key),]
d3<- head(d2,15)
d3$songs_id<-row.names(d3)
remove(d2)
p4 <- 
  ggplot(d3,aes(songs_id,key)) +
  geom_bar(stat='identity',fill="#00394C") +
  scale_y_log10() +
  theme(legend.position = "none")+coord_flip()
layout <- matrix(c(1,2,3,4),2,2,byrow=TRUE)
multiplot(p1, p2, p3, p4, layout=layout)
```
We have replaced the actual artist names, composer names and song ids with dummy ids. We will use these shortened ids for feature generation at a later stage
## Categorical Features from songs and members data - 2
Now, let's look into frequencies of top 15 lyricists, cities, languages and *registered_via* from the training data. Note the logarithmic y-axes:
```{r  split=FALSE, fig.align = 'default', warning = FALSE, fig.cap ="Fig. 3", out.width="100%"}
d2 <- aggregate(key~lyricist,data=master_df_w_song_member_details_train,FUN=length)
d2<- d2[order(-d2$key),]
d3<- head(d2,15)
d3$lyricist_id<-row.names(d3)
remove(d2)
p1 <- 
  ggplot(d3,aes(lyricist_id,key)) +
  geom_bar(stat='identity',fill="#00394C") +
  scale_y_log10() +
  theme(legend.position = "none")+coord_flip()
d2 <- aggregate(key~city,data=master_df_w_song_member_details_train,FUN=length)
d2<- d2[order(-d2$key),]
d3<- head(d2,15)
d3$city_id<-row.names(d3)
remove(d2)
p2 <- 
  ggplot(d3,aes(city_id,key)) +
  geom_bar(stat='identity',fill="#00394C") +
  scale_y_log10() +
  theme(legend.position = "none")+coord_flip()
d2 <- aggregate(key~language,data=master_df_w_song_member_details_train,FUN=length)
d2<- d2[order(-d2$key),]
d3<- head(d2,15)
d3$language_id<-row.names(d3) 
remove(d2)
p3 <- 
  ggplot(d3,aes(language_id,key)) +
  geom_bar(stat='identity',fill="#00394C") +
  scale_y_log10() +
  theme(legend.position = "none")+coord_flip()
d2 <- aggregate(key~registered_via,data=master_df_w_song_member_details_train,FUN=length)
d2<- d2[order(-d2$key),]
d3<- head(d2,15)
d3$registered_approach_id<-row.names(d3) 
remove(d2)
p4 <- 
  ggplot(d3,aes(registered_approach_id,key)) +
  geom_bar(stat='identity',fill="#00394C") +
  scale_y_log10() +
  theme(legend.position = "none")+coord_flip()
layout <- matrix(c(1,2,3,4),2,2,byrow=TRUE)
multiplot(p1, p2, p3, p4, layout=layout)
```
We have replaced the actual city, lyricist names, languages and registered_approaches with dummy ids. We will use these shortened ids for feature generation at a later stage.
# Combines feature visualizations {.tabset .tabset-fade .tabset-pills}
title: 
---
title: 'Pallab Sarkar - KKBox Music Recommendation EDA'
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: cosmo
    highlight: tango
    code_folding: hide
---
---
title: 'Pallab Sarkar - KKBox Music Recommendation EDA'
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: cosmo
    highlight: tango
    code_folding: hide
------
title: 'Pallab Sarkar - KKBox Music Recommendation EDA'
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: cosmo
    highlight: tango
    code_folding: hide
---
---
library('ggplot2') # visualisation
library('scales') # visualisation
library('grid') # visualisation
library('ggthemes') # visualisation
library('gridExtra') # visualisation
library('RColorBrewer') # visualisation
library('corrplot') # visualisation
utils:::menuInstallPkgs()
utils:::menuInstallPkgs()
library('ggpubr') # visualisation
install.packages("package name") 
출처: http://rfriend.tistory.com/7 [R, Python 분석과 프로그래밍 (by R Friend)]
install.packages("package name") 
출처: http://rfriend.tistory.com/7 [R, Python 분석과 프로그래밍 (by R Friend)]
install.packages("ggplot2") 
install.packages("scales") 
install.packages("grid") 
install.packages("ggthemes") 
install.packages("gridExtra") 
install.packages("RColorBrewer") 
install.packages("corrplot") 
install.packages("ggpubr") 
install.packages("dplyr") 
install.packages("readr") 
install.packages("data.table") 
install.packages("tibble") 
install.packages("tidyr") 
install.packages("stringr") 
install.packages("forcats") 
install.packages("forcats") 
install.packages("alluvial") 
install.packages("ggfortify") 
install.packages("ggrepel") 
install.packages("ggridges") 
install.packages("VIM") 
install.packages("plotly") 
install.packages("ggforce") 
train <- as.tibble(fread('../input/train.csv'))
test <- as.tibble(fread('../input/test.csv'))
songs<-as.tibble(fread('../input/songs.csv'))
members<-as.tibble(fread('../input/members.csv'))
library('ggplot2') # visualisation
library('scales') # visualisation
library('grid') # visualisation
library('ggthemes') # visualisation
library('gridExtra') # visualisation
library('RColorBrewer') # visualisation
library('corrplot') # visualisation
library('ggpubr') # visualisation
library('dplyr') # data manipulation
library('readr') # input/output
library('data.table') # data manipulation
library('tibble') # data wrangling
library('tidyr') # data wrangling
library('stringr') # string manipulation
save.image("C:\\Users\\KANG JUN HU\\Documents\\Google Drive\\3.Purdue_Capstone_Design_Project\\XLargeKSQ\\소스코드\\.RData")
